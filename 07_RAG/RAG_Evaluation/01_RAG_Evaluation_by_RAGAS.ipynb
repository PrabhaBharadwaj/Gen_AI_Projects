{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-8eQQrzQOIO"
      },
      "source": [
        "# **RAG Evaluation**\n",
        "- RAG workflow evaluated in 2 parts.\n",
        "1. Retrieval\n",
        "2. Generation\n",
        "\n",
        "# **Different RAG Evaluation Tech:**\n",
        "**Inside this will have multiple Matrics to evaluate Retrieval or  Generation Part**\n",
        "\n",
        "- **RAGAS:** https://docs.ragas.io/en/latest/concepts/metrics/context_recall.html\n",
        "- **TrueLence:** https://www.trulens.org/trulens_eval/getting_started/core_concepts/rag_triad/\n",
        "- **ARES** :https://github.com/stanford-futuredata/ARES?tab=readme-ov-file#section3\n",
        "\n",
        "- **ROUGE** is evaluation matric for **Text summrization task**\n",
        "- **BLEU** is  evaluation matric for **Text translation task**\n",
        "\n",
        "#### **This script executed in Colab notebook**\n",
        "\n",
        "- Here in **Langchain** approch we used **Vector-DB Weaviate In memory DB**\n",
        "  -  **from weaviate.embedded import EmbeddedOptions**\n",
        "\n",
        "\n",
        "## **Steps Followed for RAG[Langchain / LlamaIndex Framework]**:\n",
        "- **Ingest Data**  from Website .txt\n",
        "- Convert data to **Chunks**\n",
        "- Apply Embedding using **OpenAI Embedding model**\n",
        "- Store Embedding in **Weaviate In memory DB**\n",
        "- Use **LLM** Model, here **OpenAI- GPT-3.5-Turbo** used and passed **User Q + Vector DB Retrival + System Prompt**\n",
        "- This gives **End result** and then applied **Evaluation**\n",
        "\n",
        "**EVALUATION**\n",
        "- Here we tried **RAGS** Technique. Inside this will have multiple **Matrics** to **evaluate Retrieval or  Generation Part**. Few example:\n",
        "\n",
        "- **Retrieval Part Matrics**\n",
        "  -  context_recall\n",
        "  -  context_precision\n",
        "\n",
        "- **Generation Part Matrics**\n",
        "  - faithfulness\n",
        "  -  answer_relevancy\n",
        "  \n",
        "- **Other**\n",
        "  - answer_similarity\n",
        "  - answer_correctness\n",
        "\n",
        "- Here we **provided sample Question with Groundtruth manually**, but in production scenario, we can use other **LLM model to produce groundtruth or behave as Critic model** to evaluate current model\n",
        "\n",
        "\n",
        "### To evaluate the RAG pipeline, RAGAs expects the following information:\n",
        "\n",
        "- **question:** The user query that is the input of the RAG pipeline. The input.\n",
        "- **answer:** The generated answer from the RAG pipeline. The output.\n",
        "- **contexts:** The contexts retrieved from the external knowledge source used to answer the question.\n",
        "- **ground_truths:** The ground truth answer to the question. This is the only human-annotated information. This information is only required for the metric context_recall (see Evaluation Metrics)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v3BlL8NEDfDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e13c926-d009-4f98-a4b1-e223fcda25e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.0/116.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai weaviate-client ragas -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTMgxXCZTKfE"
      },
      "source": [
        "## **Read external data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hoD3TN19Dz9a"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U4L8bolZEPhZ"
      },
      "outputs": [],
      "source": [
        "url=\"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/docs/modules/state_of_the_union.txt\"\n",
        "res = requests.get(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zu-sEBtiEoNf",
        "outputId": "49f0d6fe-a0a9-4ca3-fb2f-14a284086f98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and th'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "res.text[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PqS6vHCXEjXZ"
      },
      "outputs": [],
      "source": [
        "#Write URL extracted data as state_of_the_union.txt in colab space, It automatically inside content folder\n",
        "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
        "    f.write(res.text)\n",
        "\n",
        "#Read this state_of_the_union.txt using Langchain document_loaders TextLoader\n",
        "loader=TextLoader(\"./state_of_the_union.txt\")\n",
        "documents=loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzP51Q1PTeBz"
      },
      "source": [
        "## **Chunk the document**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9XsR_ggFErvR"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter=CharacterTextSplitter(chunk_size=500,chunk_overlap=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "wGnVecn9FAeJ",
        "outputId": "06c019e7-9672-4206-b1c2-3feb602f3db0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \\n\\nIn this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \\n\\nLet each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "chunks=text_splitter.split_documents(documents)\n",
        "chunks[2].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdsjcE0sFaSh",
        "outputId": "7973656f-7905-4933-c489-3e1dceff2fe7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(chunks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Ogb1clTkLb"
      },
      "source": [
        "## **Embedding and Create Vecor DB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JbPCFgqOFpwh"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Weaviate\n",
        "import weaviate\n",
        "from weaviate.embedded import EmbeddedOptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cqW-w0XeF-9R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"]=OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK0nkEUtGIYh",
        "outputId": "70cd8cb0-fe82-4d83-9a77-1e8bac131538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary /root/.cache/weaviate-embedded did not exist. Downloading binary from https://github.com/weaviate/weaviate/releases/download/v1.23.7/weaviate-v1.23.7-Linux-amd64.tar.gz\n",
            "Started /root/.cache/weaviate-embedded: process ID 635\n"
          ]
        }
      ],
      "source": [
        "#This client helps to save embeddings in weaviate in memory\n",
        "weaviate_client=weaviate.Client(\n",
        "    embedded_options=EmbeddedOptions()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1ql4xrAJGd4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67d7cc4-692b-4bff-9361-53508d8ad4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "#Create Weaviate Vector DB\n",
        "vectorstore=Weaviate.from_documents(\n",
        "    client=weaviate_client,\n",
        "    documents=chunks,\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    by_text=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xl8d_YlcHBux"
      },
      "outputs": [],
      "source": [
        "#Create retriever object from vector db\n",
        "retriever=vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO2hRsBNT-4M"
      },
      "source": [
        "## **Create Langchain prompt and pass to LLM Model with User Q and Retrived O/P**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "S_1sXKtUHGlk"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Use LLM Model - gpt-3.5-turbo**"
      ],
      "metadata": {
        "id": "XDgnOO0IP-8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pws26QULHVCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0336790-11f0-48ea-c709-3a2175349463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P46r_iI9UK9D"
      },
      "source": [
        "#### **Langchain prompt template**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fb0ts_TUHetW"
      },
      "outputs": [],
      "source": [
        "# Define prompt template\n",
        "template = \"\"\"You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Use two sentences maximum and keep the answer concise.\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CPH3tLVtHlQi"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(template)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5l-sFT9cHmoy"
      },
      "outputs": [],
      "source": [
        "#Create Chain pipeline\n",
        "rag_chain=(\n",
        "     #Runtime Q assigned to question and then passed to retriever and retrivers O/P passed as Context\n",
        "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
        "          | prompt\n",
        "          | llm\n",
        "          | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test/Invoke LLM Model\n",
        "res = rag_chain.invoke(\"what did the President say about Justic Breyer?\")\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "gGuiiFq8ZCPB",
        "outputId": "329a5fd7-07e3-4da3-98fa-86ba781639b4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The President honored Justice Stephen Breyer for his service and mentioned that Judge Ketanji Brown Jackson will continue Justice Breyer's legacy of excellence.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HVu3fjdjIEtq",
        "outputId": "887f0914-7be6-43bd-87b6-2b16924fc559"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and th'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "res.text[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUWRTTEKUSns"
      },
      "source": [
        "# **Evaluation - RAGAS**\n",
        "- Create **List of user Q**\n",
        "- Create **List of groud_truths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9Dz6DfRsInzx"
      },
      "outputs": [],
      "source": [
        "# List of user Q\n",
        "questions=[\"what did the President say about Justic Breyer?\",\n",
        "           \"What did the President say abou Intel's CEO?\",\n",
        "           \"What did the President say about gun violence?\"\n",
        "\n",
        "           ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "t8V3TsHeJKNK"
      },
      "outputs": [],
      "source": [
        "# List of Ground Truth/Actual Ans for User Q\n",
        "#WARNING:ragas.validation:passing column names as 'ground_truths' is deprecated\n",
        "#and will be removed in the next version, please use 'ground_truth' instead.\n",
        "#Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths\n",
        "\n",
        "#If you are not interested in the **context_recall** metric, you don’t need to provide the ground_truths information.\n",
        "\n",
        "ground_truths=[[\"The president said that Justice Breyer has dedicated his life to serve the country and thanked him for his service.\"],\n",
        "              [\"The president said that Pat Gelsinger is ready to increase Intel's investment to $100 billion.\"],\n",
        "              [\"The president asked Congress to pass proven measures to reduce gun violence.\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EevrMujMJVpz"
      },
      "outputs": [],
      "source": [
        "#Create List\n",
        "answer=[]  #Generated answer\n",
        "context=[]  # Context for User Q frm vector DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rUkcsda9LDWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4facf065-ba33-4aff-add4-885f9c24bea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "#Loop through all Q and get Generated ans and Context\n",
        "for query in questions:\n",
        "  answer.append(rag_chain.invoke(query))  #Generated ans\n",
        "  context.append([docs.page_content  for docs in retriever.get_relevant_documents(query)]) # Context for User Q frm vector DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0tkUe2SM6GF",
        "outputId": "ed81e18d-468f-4e17-9708-12676bef6273"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"The President honored Justice Stephen Breyer for his service and mentioned nominating Judge Ketanji Brown Jackson to continue Breyer's legacy.\",\n",
              " \"The President mentioned that Intel's CEO, Pat Gelsinger, is ready to increase their investment from $20 billion to $100 billion, which would be one of the biggest investments in manufacturing in American history.\",\n",
              " 'The President called for Congress to pass measures to reduce gun violence, including universal background checks and a ban on assault weapons and high-capacity magazines. He emphasized the need to crack down on gun trafficking and ghost guns to keep communities safe.']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgyF6GawM7ZS",
        "outputId": "fb860338-a1ac-4ede-94d7-3460e63cfaa7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.',\n",
              "  'And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.',\n",
              "  'A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system.',\n",
              "  'As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \\n\\nWhile it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice.'],\n",
              " ['But that’s just the beginning. \\n\\nIntel’s CEO, Pat Gelsinger, who is here tonight, told me they are ready to increase their investment from  \\n$20 billion to $100 billion. \\n\\nThat would be one of the biggest investments in manufacturing in American history. \\n\\nAnd all they’re waiting for is for you to pass this bill. \\n\\nSo let’s not wait any longer. Send it to my desk. I’ll sign it.  \\n\\nAnd we will really take off. \\n\\nAnd Intel is not alone. \\n\\nThere’s something happening in America.',\n",
              "  'This is where Intel, the American company that helped build Silicon Valley, is going to build its $20 billion semiconductor “mega site”. \\n\\nUp to eight state-of-the-art factories in one place. 10,000 new good-paying jobs. \\n\\nSome of the most sophisticated manufacturing in the world to make computer chips the size of a fingertip that power the world and our everyday lives. \\n\\nSmartphones. The Internet. Technology we have yet to invent. \\n\\nBut that’s just the beginning.',\n",
              "  'For the past 40 years we were told that if we gave tax breaks to those at the very top, the benefits would trickle down to everyone else. \\n\\nBut that trickle-down theory led to weaker economic growth, lower wages, bigger deficits, and the widest gap between those at the top and everyone else in nearly a century. \\n\\nVice President Harris and I ran for office with a new economic vision for America.',\n",
              "  'As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \\n\\nWhile it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice.'],\n",
              " ['And I ask Congress to pass proven measures to reduce gun violence. Pass universal background checks. Why should anyone on a terrorist list be able to purchase a weapon? \\n\\nBan assault weapons and high-capacity magazines. \\n\\nRepeal the liability shield that makes gun manufacturers the only industry in America that can’t be sued. \\n\\nThese laws don’t infringe on the Second Amendment. They save lives.',\n",
              "  'As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \\n\\nWhile it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice.',\n",
              "  'Let’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \\n\\nWe can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.',\n",
              "  'We should all agree: The answer is not to Defund the police. The answer is to FUND the police with the resources and training they need to protect our communities. \\n\\nI ask Democrats and Republicans alike: Pass my budget and keep our neighborhoods safe.  \\n\\nAnd I will keep doing everything in my power to crack down on gun trafficking and ghost guns you can buy online and make at home—they have no serial numbers and can’t be traced.']]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He4qySsJVNDW"
      },
      "source": [
        "## **Create Dictionary of Q,Uns,Context,Groundtruth**\n",
        "- User Q,\n",
        "- Genereated Ans,\n",
        "- Vector db extracted Context,\n",
        "- Ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "o8vFPC-XJcXx"
      },
      "outputs": [],
      "source": [
        "# Create To dict\n",
        "data = {\n",
        "    \"question\": questions,\n",
        "    \"answer\": answer,\n",
        "    \"contexts\": context,\n",
        "    \"ground_truths\": ground_truths\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MJzbNH6ddow"
      },
      "source": [
        "## **Convert dictionary as Hugging face dataset format**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "w7LGZAbYobmh"
      },
      "outputs": [],
      "source": [
        "#!pip install Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf7121l-K5CL",
        "outputId": "044945b1-3a21-413a-975d-84f3cf5f58b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'answer', 'contexts', 'ground_truths'],\n",
              "    num_rows: 3\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#Convert dictionary as Hugging face dataset format\n",
        "from datasets import Dataset\n",
        "dataset=Dataset.from_dict(data)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkVWWKy9Vh89"
      },
      "source": [
        "## **Apply RAG Evaluation Technique**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "K9Nr15uVNWN4"
      },
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Some time it fails in this part, terminate session and rerun\n",
        "#Main RAG Evaluation\n",
        "result = evaluate(\n",
        "    dataset = dataset,\n",
        "    metrics=[\n",
        "        context_precision,\n",
        "        context_recall,\n",
        "        faithfulness,\n",
        "        answer_relevancy,\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "f1fb2d02cdaf4dc2acc87b6a08143650",
            "67b19a318aef41d9a6418d6c727309a0",
            "7cba910989384cf2ac6609825aa08b4c",
            "8045b5083dc54081be88c4365b0da593",
            "1829f20e191647289d137ae1fc3afda2",
            "fe7e97fb81034299802fe6e5e1247425",
            "5bded7e6deb74371b10d7323ef9e3c1d",
            "9f1fda607b414ece8d3000a0c7d68d37",
            "ec807340bad146f7a739e2032fb51b65",
            "252546cd54284973b498bf0c60a07b60",
            "deabc4928cf4483a842e95ea64c776d3"
          ]
        },
        "id": "_4eRMpmxQlAM",
        "outputId": "94e5c090-d160-4ef9-d67b-a259507364f7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ragas.validation:passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1fb2d02cdaf4dc2acc87b6a08143650"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "AFIT-pkpOCyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c085a6c4-1fa7-40cf-fc8b-8da6dd9d693f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context_precision': 1.0000, 'context_recall': 1.0000, 'faithfulness': 1.0000, 'answer_relevancy': 0.8687}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "#Average Matrics value over 3 records\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ESPmG2dFOH0j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "80fe01a6-03d6-447a-9185-d030024a2eb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          question  \\\n",
              "0  what did the President say about Justic Breyer?   \n",
              "1     What did the President say abou Intel's CEO?   \n",
              "2   What did the President say about gun violence?   \n",
              "\n",
              "                                              answer  \\\n",
              "0  The President honored Justice Stephen Breyer f...   \n",
              "1  The President mentioned that Intel's CEO, Pat ...   \n",
              "2  The President called for Congress to pass meas...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [Tonight, I’d like to honor someone who has de...   \n",
              "1  [But that’s just the beginning. \\n\\nIntel’s CE...   \n",
              "2  [And I ask Congress to pass proven measures to...   \n",
              "\n",
              "                                       ground_truths  \\\n",
              "0  [The president said that Justice Breyer has de...   \n",
              "1  [The president said that Pat Gelsinger is read...   \n",
              "2  [The president asked Congress to pass proven m...   \n",
              "\n",
              "                                        ground_truth  context_precision  \\\n",
              "0  The president said that Justice Breyer has ded...                1.0   \n",
              "1  The president said that Pat Gelsinger is ready...                1.0   \n",
              "2  The president asked Congress to pass proven me...                1.0   \n",
              "\n",
              "   context_recall  faithfulness  answer_relevancy  \n",
              "0             1.0           1.0          0.825979  \n",
              "1             1.0           1.0          0.866591  \n",
              "2             1.0           1.0          0.913553  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aed29bb9-2bb2-4027-b774-de2677cf1fe2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truths</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what did the President say about Justic Breyer?</td>\n",
              "      <td>The President honored Justice Stephen Breyer f...</td>\n",
              "      <td>[Tonight, I’d like to honor someone who has de...</td>\n",
              "      <td>[The president said that Justice Breyer has de...</td>\n",
              "      <td>The president said that Justice Breyer has ded...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.825979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What did the President say abou Intel's CEO?</td>\n",
              "      <td>The President mentioned that Intel's CEO, Pat ...</td>\n",
              "      <td>[But that’s just the beginning. \\n\\nIntel’s CE...</td>\n",
              "      <td>[The president said that Pat Gelsinger is read...</td>\n",
              "      <td>The president said that Pat Gelsinger is ready...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.866591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What did the President say about gun violence?</td>\n",
              "      <td>The President called for Congress to pass meas...</td>\n",
              "      <td>[And I ask Congress to pass proven measures to...</td>\n",
              "      <td>[The president asked Congress to pass proven m...</td>\n",
              "      <td>The president asked Congress to pass proven me...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.913553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aed29bb9-2bb2-4027-b774-de2677cf1fe2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aed29bb9-2bb2-4027-b774-de2677cf1fe2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aed29bb9-2bb2-4027-b774-de2677cf1fe2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f407956f-a071-4dfb-b7a2-16246e700d1a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f407956f-a071-4dfb-b7a2-16246e700d1a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f407956f-a071-4dfb-b7a2-16246e700d1a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0e52bf7c-d017-4ee4-9d4a-6aa04aab7d89\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('evaluation_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0e52bf7c-d017-4ee4-9d4a-6aa04aab7d89 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('evaluation_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "evaluation_df",
              "summary": "{\n  \"name\": \"evaluation_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"what did the President say about Justic Breyer?\",\n          \"What did the President say abou Intel's CEO?\",\n          \"What did the President say about gun violence?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"The President honored Justice Stephen Breyer for his service and mentioned nominating Judge Ketanji Brown Jackson to continue Breyer's legacy.\",\n          \"The President mentioned that Intel's CEO, Pat Gelsinger, is ready to increase their investment from $20 billion to $100 billion, which would be one of the biggest investments in manufacturing in American history.\",\n          \"The President called for Congress to pass measures to reduce gun violence, including universal background checks and a ban on assault weapons and high-capacity magazines. He emphasized the need to crack down on gun trafficking and ghost guns to keep communities safe.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truths\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"The president said that Justice Breyer has dedicated his life to serve the country and thanked him for his service.\",\n          \"The president said that Pat Gelsinger is ready to increase Intel's investment to $100 billion.\",\n          \"The president asked Congress to pass proven measures to reduce gun violence.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8867515847990063e-11,\n        \"min\": 0.9999999999,\n        \"max\": 0.99999999995,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.9999999999,\n          0.99999999995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"faithfulness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.043825238200412495,\n        \"min\": 0.8259792561318021,\n        \"max\": 0.9135530061872347,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8259792561318021\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#Convert to pandas df\n",
        "evaluation_df=result.to_pandas()\n",
        "evaluation_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "xvZEKRENOMc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "be4fdbc8-bab5-4433-9b9c-b1c7dbba276e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          question  \\\n",
              "0  what did the President say about Justic Breyer?   \n",
              "\n",
              "                                                                                                answer  \\\n",
              "0  The President honored Justice Stephen Breyer for his service and mentioned nominating Judge Keta...   \n",
              "\n",
              "                                                                                              contexts  \\\n",
              "0  [Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice St...   \n",
              "\n",
              "                                                                                         ground_truths  \\\n",
              "0  [The president said that Justice Breyer has dedicated his life to serve the country and thanked ...   \n",
              "\n",
              "                                                                                          ground_truth  \\\n",
              "0  The president said that Justice Breyer has dedicated his life to serve the country and thanked h...   \n",
              "\n",
              "   context_precision  context_recall  faithfulness  answer_relevancy  \n",
              "0                1.0             1.0           1.0          0.825979  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7851e5c9-7d7c-4317-8868-8d4cae8a4ff2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truths</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what did the President say about Justic Breyer?</td>\n",
              "      <td>The President honored Justice Stephen Breyer for his service and mentioned nominating Judge Keta...</td>\n",
              "      <td>[Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice St...</td>\n",
              "      <td>[The president said that Justice Breyer has dedicated his life to serve the country and thanked ...</td>\n",
              "      <td>The president said that Justice Breyer has dedicated his life to serve the country and thanked h...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.825979</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7851e5c9-7d7c-4317-8868-8d4cae8a4ff2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7851e5c9-7d7c-4317-8868-8d4cae8a4ff2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7851e5c9-7d7c-4317-8868-8d4cae8a4ff2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"evaluation_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"what did the President say about Justic Breyer?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The President honored Justice Stephen Breyer for his service and mentioned nominating Judge Ketanji Brown Jackson to continue Breyer's legacy.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truths\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The president said that Justice Breyer has dedicated his life to serve the country and thanked him for his service.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.99999999995,\n        \"max\": 0.99999999995,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.99999999995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"faithfulness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8259792561318021,\n        \"max\": 0.8259792561318021,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8259792561318021\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "#import pandas as pd\n",
        "#pd.set_option('display.max_colwidth', 100)\n",
        "evaluation_df.iloc[[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "uMAv2kiYPL6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aeaab0ca-3baa-4886-de38-49475697da78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what did the President say about Justic Breyer?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "#data\n",
        "#this is my actual User query\n",
        "evaluation_df.iloc[0,:].question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "H53eHwv3Ph7C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "41a68334-b66a-425d-93c9-5f6ab50f39c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The President honored Justice Stephen Breyer for his service and mentioned nominating Judge Ketanji Brown Jackson to continue Breyer's legacy.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "#predicted\n",
        "#generation of the model\n",
        "evaluation_df.iloc[0,:].answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "e4RchGjuPlu_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "be80f9e1-0858-4530-d9a2-c6233e792fb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The president said that Justice Breyer has dedicated his life to serve the country and thanked him for his service.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "#actual/Ground Truth\n",
        "#actual answer(manually we have written this answer)(this could be llm generated)\n",
        "evaluation_df.iloc[0,:].ground_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "vos6bzpFPtfM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "761ff238-a058-4334-8294-4740a261c203"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "#Retrived Context\n",
        "#retrieval result(context)\n",
        "evaluation_df.iloc[0,:].contexts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjgoF7p9Q3jE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "context_precision                                                  1.0\n",
        "context_recall                                                     1.0\n",
        "faithfulness                                                       1.0\n",
        "answer_relevancy                                               0.83073\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ0tICIfmn15"
      },
      "source": [
        "# **Try our own LLM Model and embedding to evaluate**\n",
        "- By default RAGA'S use OPENAI chat 3.5 Turbo 16 model, so we can change to our own LLM modelbe this way(Mentioning LLM in evaluate part)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwQgEL5VmtXv"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "from langchain_openai.chat_models import AzureChatOpenAI\n",
        "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
        "\n",
        "azure_model = AzureChatOpenAI(\n",
        "openai_api_version = \"\",\n",
        "azure_endpoint = \"\",\n",
        "azure_deployment = \"\",\n",
        "model = \"\",\n",
        "validate_base_url  = \"\"\n",
        ")\n",
        "\n",
        "azure_embeddings = AzureOpenAIEmbeddings(\n",
        "openai_api_version = \"\",\n",
        "azure_endpoint = \"\",\n",
        "azure_deployment = \"\",\n",
        "model = \"\",\n",
        "validate_base_url  = \"\"\n",
        ")\n",
        "\n",
        "result = evaluate(dataset = dataset,\n",
        "                  llm = azure_model,\n",
        "                  embeddings = azure_embeddings,\n",
        "                  #is_async = True,\n",
        "                  metrics=[context_precision,\n",
        "                           context_recall,\n",
        "                           faithfulness,\n",
        "                           answer_relevancy,\n",
        "                           ],\n",
        "                  )\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#Now lets create an Langchain llm instance and wrap it with RagasLLM class.\n",
        "#Because vLLM can run in OpenAI compatibilitiy mode, we can use the ChatOpenAI class as it is with small tweaks.\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "inference_server_url = \"http://localhost:8080/v1\"\n",
        "\n",
        "# create vLLM Langchain instance\n",
        "chat = ChatOpenAI(\n",
        "    model=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
        "    openai_api_key=\"no-key\",\n",
        "    openai_api_base=inference_server_url,\n",
        "    max_tokens=5,\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# use the Ragas LangchainLLM wrapper to create a RagasLLM instance\n",
        "vllm = LangchainLLMWrapper(chat)\n",
        "\n",
        "#  In ragas.evaluate class, it uses default LLM model is OpenAI's gpt-3.5-turbo-16k, It may fail with token Limit\n",
        "#To avoid this issue we can Bring our own LLMs as vllm\n",
        "context_precision.llm = vllm\n",
        "context_recall.llm = vllm\n",
        "faithfulness.llm = vllm\n",
        "answer_relevancy.llm = vllm\n",
        "\n",
        "\n",
        "#WARNING:ragas.validation:passing column names as 'ground_truths' is deprecated\n",
        "#and will be removed in the next version, please use 'ground_truth' instead.\n",
        "#Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths\n",
        "\n",
        "\n",
        "result=evaluate(\n",
        "    dataset=dataset,\n",
        "    #List of Evaluation metrics\n",
        "    metrics=[\n",
        "        context_precision,\n",
        "        context_recall,\n",
        "        faithfulness,\n",
        "        answer_relevancy,\n",
        "    ]\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Qu6pdnaHV74W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf_qnmPOfCOQ"
      },
      "source": [
        "# **Test Evaluation matrics value with different sample with answer hardcoded**\n",
        "- answer_similarity\n",
        "- answer_correctness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1dTb6TdWtiU"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from ragas.metrics import answer_similarity\n",
        "from ragas import evaluate\n",
        "\n",
        "\n",
        "data_samples = {\n",
        "    'question': ['When was the first super bowl?', 'Who won the most super bowls?'],\n",
        "    'answer': ['The first superbowl was held on Jan 15, 1967', 'The most super bowls have been won by The New England Patriots'],\n",
        "    'ground_truth': ['The first superbowl was held on January 15, 1967', 'The New England Patriots have won the Super Bowl a record six times']\n",
        "}\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "score = evaluate(dataset,metrics=[answer_similarity]) # Check only answer_similarity\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft2R0c-SWxDS"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from ragas.metrics import faithfulness, answer_correctness\n",
        "from ragas import evaluate\n",
        "\n",
        "data_samples = {\n",
        "    'question': ['When was the first super bowl?', 'Who won the most super bowls?'],\n",
        "    'answer': ['The first superbowl was held on Jan 15, 1967', 'The most super bowls have been won by The New England Patriots'],\n",
        "    'ground_truth': ['The first superbowl was held on January 15, 1967', 'The New England Patriots have won the Super Bowl a record six times']\n",
        "}\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "score = evaluate(dataset,metrics=[answer_correctness]) # Check only answer_correctness\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **END**"
      ],
      "metadata": {
        "id": "Q6KnXUcxYM8C"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f1fb2d02cdaf4dc2acc87b6a08143650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67b19a318aef41d9a6418d6c727309a0",
              "IPY_MODEL_7cba910989384cf2ac6609825aa08b4c",
              "IPY_MODEL_8045b5083dc54081be88c4365b0da593"
            ],
            "layout": "IPY_MODEL_1829f20e191647289d137ae1fc3afda2"
          }
        },
        "67b19a318aef41d9a6418d6c727309a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe7e97fb81034299802fe6e5e1247425",
            "placeholder": "​",
            "style": "IPY_MODEL_5bded7e6deb74371b10d7323ef9e3c1d",
            "value": "Evaluating: 100%"
          }
        },
        "7cba910989384cf2ac6609825aa08b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f1fda607b414ece8d3000a0c7d68d37",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec807340bad146f7a739e2032fb51b65",
            "value": 12
          }
        },
        "8045b5083dc54081be88c4365b0da593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_252546cd54284973b498bf0c60a07b60",
            "placeholder": "​",
            "style": "IPY_MODEL_deabc4928cf4483a842e95ea64c776d3",
            "value": " 12/12 [07:19&lt;00:00, 52.09s/it]"
          }
        },
        "1829f20e191647289d137ae1fc3afda2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe7e97fb81034299802fe6e5e1247425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bded7e6deb74371b10d7323ef9e3c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f1fda607b414ece8d3000a0c7d68d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec807340bad146f7a739e2032fb51b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "252546cd54284973b498bf0c60a07b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deabc4928cf4483a842e95ea64c776d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}