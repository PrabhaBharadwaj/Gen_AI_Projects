{"cells":[{"cell_type":"markdown","id":"9b61ca09-df53-48a9-ae2b-b80ce5f8eea0","metadata":{"id":"9b61ca09-df53-48a9-ae2b-b80ce5f8eea0"},"source":["<center><a href=\"https://www.pieriantraining.com/\" ><img src=\"../PTCenteredPurple.png\" alt=\"Pierian Training Logo\" /></a></center>\n"]},{"cell_type":"markdown","id":"b71becfd-b5fe-4d8b-a0a1-d6795a45ef5a","metadata":{"id":"b71becfd-b5fe-4d8b-a0a1-d6795a45ef5a"},"source":["## Setting Up Authentication\n","\n","Make sure to take a look at the video to understand how to set-up and download your API key!\n","\n","There are two main ways to authenticate via your API Key:\n","1. Simply pass in your API Key as a string to your client call\n","2. Set up your Environment Variable on your computer's OS, specifically the environment variable OPENAI_API_KEY , then OpenAI() call will search for that key automatically if you don't pass in a string api key."]},{"cell_type":"code","execution_count":7,"id":"575d18c8-307c-480b-8956-3f55c72b30b7","metadata":{"id":"575d18c8-307c-480b-8956-3f55c72b30b7","executionInfo":{"status":"ok","timestamp":1735736690736,"user_tz":-480,"elapsed":836,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[],"source":["import openai\n","from openai import OpenAI"]},{"cell_type":"code","execution_count":8,"id":"5e859cea-f121-4a27-9cfc-458f59314c18","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5e859cea-f121-4a27-9cfc-458f59314c18","executionInfo":{"status":"ok","timestamp":1735736692546,"user_tz":-480,"elapsed":425,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}},"outputId":"9a014284-b09b-40cd-8120-07c11538b5fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.57.4\n"]}],"source":["print(openai.__version__)"]},{"cell_type":"code","source":["help(OpenAI)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"buc96Y8c9-zJ","executionInfo":{"status":"ok","timestamp":1735736694085,"user_tz":-480,"elapsed":971,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}},"outputId":"c170a1f8-2a17-48d1-c44b-bb1d2e317be5"},"id":"buc96Y8c9-zJ","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on class OpenAI in module openai:\n","\n","class OpenAI(openai._base_client.SyncAPIClient)\n"," |  OpenAI(*, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'Union[float, Timeout, None, NotGiven]' = NOT_GIVEN, max_retries: 'int' = 2, default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, http_client: 'httpx.Client | None' = None, _strict_response_validation: 'bool' = False) -> 'None'\n"," |  \n"," |  Method resolution order:\n"," |      OpenAI\n"," |      openai._base_client.SyncAPIClient\n"," |      openai._base_client.BaseClient\n"," |      typing.Generic\n"," |      builtins.object\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __init__(self, *, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'Union[float, Timeout, None, NotGiven]' = NOT_GIVEN, max_retries: 'int' = 2, default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, http_client: 'httpx.Client | None' = None, _strict_response_validation: 'bool' = False) -> 'None'\n"," |      Construct a new synchronous openai client instance.\n"," |      \n"," |      This automatically infers the following arguments from their corresponding environment variables if they are not provided:\n"," |      - `api_key` from `OPENAI_API_KEY`\n"," |      - `organization` from `OPENAI_ORG_ID`\n"," |      - `project` from `OPENAI_PROJECT_ID`\n"," |  \n"," |  copy(self, *, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'float | Timeout | None | NotGiven' = NOT_GIVEN, http_client: 'httpx.Client | None' = None, max_retries: 'int | NotGiven' = NOT_GIVEN, default_headers: 'Mapping[str, str] | None' = None, set_default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, set_default_query: 'Mapping[str, object] | None' = None, _extra_kwargs: 'Mapping[str, Any]' = {}) -> 'Self'\n"," |      Create a new client instance re-using the same options given to the current client with optional overriding.\n"," |  \n"," |  with_options = copy(self, *, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'float | Timeout | None | NotGiven' = NOT_GIVEN, http_client: 'httpx.Client | None' = None, max_retries: 'int | NotGiven' = NOT_GIVEN, default_headers: 'Mapping[str, str] | None' = None, set_default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, set_default_query: 'Mapping[str, object] | None' = None, _extra_kwargs: 'Mapping[str, Any]' = {}) -> 'Self'\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Readonly properties defined here:\n"," |  \n"," |  auth_headers\n"," |  \n"," |  default_headers\n"," |  \n"," |  qs\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes defined here:\n"," |  \n"," |  __annotations__ = {'api_key': 'str', 'audio': 'audio.Audio', 'batches'...\n"," |  \n"," |  __parameters__ = ()\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from openai._base_client.SyncAPIClient:\n"," |  \n"," |  __enter__(self: '_T') -> '_T'\n"," |  \n"," |  __exit__(self, exc_type: 'type[BaseException] | None', exc: 'BaseException | None', exc_tb: 'TracebackType | None') -> 'None'\n"," |  \n"," |  close(self) -> 'None'\n"," |      Close the underlying HTTPX client.\n"," |      \n"," |      The client will *not* be usable after this.\n"," |  \n"," |  delete(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, options: 'RequestOptions' = {}) -> 'ResponseT'\n"," |  \n"," |  get(self, path: 'str', *, cast_to: 'Type[ResponseT]', options: 'RequestOptions' = {}, stream: 'bool' = False, stream_cls: 'type[_StreamT] | None' = None) -> 'ResponseT | _StreamT'\n"," |  \n"," |  get_api_list(self, path: 'str', *, model: 'Type[object]', page: 'Type[SyncPageT]', body: 'Body | None' = None, options: 'RequestOptions' = {}, method: 'str' = 'get') -> 'SyncPageT'\n"," |  \n"," |  is_closed(self) -> 'bool'\n"," |  \n"," |  patch(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, options: 'RequestOptions' = {}) -> 'ResponseT'\n"," |  \n"," |  post(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, options: 'RequestOptions' = {}, files: 'RequestFiles | None' = None, stream: 'bool' = False, stream_cls: 'type[_StreamT] | None' = None) -> 'ResponseT | _StreamT'\n"," |  \n"," |  put(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, files: 'RequestFiles | None' = None, options: 'RequestOptions' = {}) -> 'ResponseT'\n"," |  \n"," |  request(self, cast_to: 'Type[ResponseT]', options: 'FinalRequestOptions', remaining_retries: 'Optional[int]' = None, *, stream: 'bool' = False, stream_cls: 'type[_StreamT] | None' = None) -> 'ResponseT | _StreamT'\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes inherited from openai._base_client.SyncAPIClient:\n"," |  \n"," |  __orig_bases__ = (openai._base_client.BaseClient[httpx.Client, openai....\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from openai._base_client.BaseClient:\n"," |  \n"," |  platform_headers(self) -> 'Dict[str, str]'\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Readonly properties inherited from openai._base_client.BaseClient:\n"," |  \n"," |  custom_auth\n"," |  \n"," |  default_query\n"," |  \n"," |  user_agent\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from openai._base_client.BaseClient:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n"," |  \n"," |  base_url\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Class methods inherited from typing.Generic:\n"," |  \n"," |  __class_getitem__(params) from builtins.type\n"," |  \n"," |  __init_subclass__(*args, **kwargs) from builtins.type\n"," |      This method is called when a class is subclassed.\n"," |      \n"," |      The default implementation does nothing. It may be\n"," |      overridden to extend subclasses.\n","\n"]}]},{"cell_type":"markdown","id":"e895d400-ae80-45e3-adf0-eb1676f0e5c0","metadata":{"id":"e895d400-ae80-45e3-adf0-eb1676f0e5c0"},"source":["Search \"How to create an environment variable on your OS, like Windows\".\n","\n","For example: https://superuser.com/questions/949560/how-do-i-set-system-environment-variables-in-windows-10\n","\n","You could also try doing this via Python, but it may only last for your current session and may not be permanent, depending on your Python permissions:"]},{"cell_type":"code","execution_count":5,"id":"c222d533-9f5c-40f0-93b0-32846ae9fbf6","metadata":{"id":"c222d533-9f5c-40f0-93b0-32846ae9fbf6","executionInfo":{"status":"ok","timestamp":1735736634282,"user_tz":-480,"elapsed":1978,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[],"source":["import os\n","from google.colab import userdata\n","\n","# os.environ['OPENAI_API_KEY'] = 'sk-sdf987k1jh24kjh...etc...'\n","OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"]},{"cell_type":"code","execution_count":10,"id":"2cb628a5-c7d7-4015-87d0-076bad181fb5","metadata":{"id":"2cb628a5-c7d7-4015-87d0-076bad181fb5","executionInfo":{"status":"ok","timestamp":1735738179078,"user_tz":-480,"elapsed":453,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[],"source":["# Once you've set-up your OpenAI API Key as an Environment Variable\n","# you can just create a client like this:\n","client = OpenAI()"]},{"cell_type":"markdown","id":"45886539-dfab-4a73-ba67-f740165c7f47","metadata":{"id":"45886539-dfab-4a73-ba67-f740165c7f47"},"source":["## Chat Completion\n","\n","The Chat Completions API is a feature of OpenAI's GPT-3 models that allows you to simulate conversations. It works by taking a series of messages as input and producing a message as output. This feature is versatile, as it can handle both multi-turn conversations (where there's a back-and-forth exchange) and single-turn tasks (where only a direct response is needed).\n","\n","Here's how you can use it:\n","\n","1. **Setting Up**: You begin by importing the OpenAI library and initializing the client, as shown in the example.\n","\n","2. **Creating a Conversation**: The core of this API is the conversation format. You use the `chat.completions.create` method, specifying the model (like \"gpt-3.5-turbo\") and a list of messages.\n","\n","3. **Understanding Messages**: Each message in the conversation is an object that has two parts: a role and content. The role can be \"system\", \"user\", or \"assistant\".\n","    - **System Message**: This is optional. It sets the initial tone or instructions for the assistant, like \"You are a helpful assistant.\"\n","    - **User Message**: This is where you, as the user, ask questions or make statements.\n","    - **Assistant Message**: This is the AI's response. You can also prefill this with examples of how you want the AI to respond.\n","\n","4. **Building the Conversation**: A typical conversation begins with a system message, followed by alternating user and assistant messages. The assistant's responses depend on the user's messages and the context provided by previous interactions.\n","\n","5. **Contextual Responses**: It's important to include the conversation history, especially when the user's messages refer to earlier parts of the conversation. Since the model doesn't remember past interactions, all necessary information must be included in the current conversation.\n","\n","6. **Handling Long Conversations**: If a conversation becomes too long for the modelâ€™s token limit, you'll need to condense or shorten it.\n","\n","This API is powerful for creating natural, interactive dialogues with an AI, whether for customer service, educational purposes, or other interactive applications. By structuring the conversation with clear roles and context, you can guide the AI to provide relevant and accurate responses."]},{"cell_type":"code","execution_count":11,"id":"7815f0f3-e821-45b9-b34e-0206ab16e715","metadata":{"id":"7815f0f3-e821-45b9-b34e-0206ab16e715","executionInfo":{"status":"ok","timestamp":1735738184372,"user_tz":-480,"elapsed":3,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[],"source":["from openai import OpenAI\n","client = OpenAI()"]},{"cell_type":"code","execution_count":12,"id":"b5075452-f83d-4557-a924-7c4c54ce9253","metadata":{"id":"b5075452-f83d-4557-a924-7c4c54ce9253","executionInfo":{"status":"ok","timestamp":1735738187261,"user_tz":-480,"elapsed":872,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[],"source":["response = client.chat.completions.create(\n","    model = 'gpt-3.5-turbo',\n","    messages = [\n","    {'role':'system','content':'You are a helpful assistant.'},\n","    {'role':'user','content':'What is the capital of France?'}\n","    ]\n","\n",")"]},{"cell_type":"code","execution_count":13,"id":"05aa85e2-5553-41f9-8e1a-442bfec6074b","metadata":{"id":"05aa85e2-5553-41f9-8e1a-442bfec6074b","outputId":"edf4dd1f-c9d2-4c33-bea5-fd03e3d7e88a","colab":{"base_uri":"https://localhost:8080/","height":186},"executionInfo":{"status":"ok","timestamp":1735738189271,"user_tz":-480,"elapsed":597,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["openai.types.chat.chat_completion.ChatCompletion"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>openai.types.chat.chat_completion.ChatCompletion</b><br/>def __init__(self, /, **data: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/openai/types/chat/chat_completion.py</a>Usage docs: https://docs.pydantic.dev/2.10/concepts/models/\n","\n","A base class for creating Pydantic models.\n","\n","Attributes:\n","    __class_vars__: The names of the class variables defined on the model.\n","    __private_attributes__: Metadata about the private attributes of the model.\n","    __signature__: The synthesized `__init__` [`Signature`][inspect.Signature] of the model.\n","\n","    __pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n","    __pydantic_core_schema__: The core schema of the model.\n","    __pydantic_custom_init__: Whether the model has a custom `__init__` function.\n","    __pydantic_decorators__: Metadata containing the decorators defined on the model.\n","        This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n","    __pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n","        __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n","    __pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n","    __pydantic_post_init__: The name of the post-init method for the model, if defined.\n","    __pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n","    __pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n","    __pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n","\n","    __pydantic_fields__: A dictionary of field names and their corresponding [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n","    __pydantic_computed_fields__: A dictionary of computed field names and their corresponding [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.\n","\n","    __pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n","        is set to `&#x27;allow&#x27;`.\n","    __pydantic_fields_set__: The names of fields explicitly set during instantiation.\n","    __pydantic_private__: Values of private attributes set on the model instance.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 43);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":13}],"source":["type(response)"]},{"cell_type":"code","execution_count":14,"id":"8dcc20f4-55a1-4b72-8d17-1b8150235438","metadata":{"id":"8dcc20f4-55a1-4b72-8d17-1b8150235438","outputId":"4b2cf656-1ddc-41b2-87e6-d1720e39d31e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735738195852,"user_tz":-480,"elapsed":410,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatCompletion(id='chatcmpl-Akt58LpVrxzuqMv7VkhPa1Zwsnxfc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of France is Paris.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1735738186, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=8, prompt_tokens=24, total_tokens=32, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"]},"metadata":{},"execution_count":14}],"source":["response"]},{"cell_type":"code","execution_count":15,"id":"4e240bf4-4bd1-4e56-82da-18bf9b77eaf3","metadata":{"id":"4e240bf4-4bd1-4e56-82da-18bf9b77eaf3","outputId":"d891c3a5-8b81-42c6-f0b5-06d8bc867561","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1735738198995,"user_tz":-480,"elapsed":406,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The capital of France is Paris.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}],"source":["response.choices[0].message.content"]},{"cell_type":"markdown","id":"17cdfa3a-ad07-4755-be54-8d7c086217dc","metadata":{"id":"17cdfa3a-ad07-4755-be54-8d7c086217dc"},"source":["### Updating System Prompt"]},{"cell_type":"code","execution_count":16,"id":"e8e923e9-3f35-45d3-a14c-cc6b37599b02","metadata":{"id":"e8e923e9-3f35-45d3-a14c-cc6b37599b02","executionInfo":{"status":"ok","timestamp":1735738212374,"user_tz":-480,"elapsed":1340,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[],"source":["response = client.chat.completions.create(\n","    model = 'gpt-3.5-turbo',\n","    messages = [\n","    {'role':'system','content':'You are a rude and sarcastic person, that makes fun of people'},\n","    {'role':'user','content':'What is the capital of France?'}\n","    ]\n","\n",")"]},{"cell_type":"code","execution_count":17,"id":"4a8e5073-d20f-4ebb-a41c-da07092a2d7c","metadata":{"id":"4a8e5073-d20f-4ebb-a41c-da07092a2d7c","outputId":"788b96f5-0448-47ee-c47a-7345cf33cebc","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1735738216900,"user_tz":-480,"elapsed":424,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Oh wow, did you really just ask that? I didn't realize we were playing a game of trivia for kindergartners. It's Paris, in case you weren't sure. But hey, thanks for keeping me on my toes with those tough questions.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}],"source":["response.choices[0].message.content"]},{"cell_type":"code","execution_count":18,"id":"ca9ef35a-c2bf-4036-b309-ae0a529b0e60","metadata":{"id":"ca9ef35a-c2bf-4036-b309-ae0a529b0e60","executionInfo":{"status":"ok","timestamp":1735738222988,"user_tz":-480,"elapsed":436,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[],"source":["response = client.chat.completions.create(\n","    model = 'gpt-3.5-turbo',\n","    messages = [\n","    {'role':'system','content':'You are a polite customer support staff of Dynamics Inc.'},\n","    {'role':'user','content':'What is the capital of France?'}\n","    ]\n","\n",")"]},{"cell_type":"code","execution_count":19,"id":"3c1c5cc1-18a7-449f-9401-bb0acb679cc2","metadata":{"id":"3c1c5cc1-18a7-449f-9401-bb0acb679cc2","outputId":"a0b0d5b1-b0bb-44a3-914b-a31d57a60a67","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1735738224679,"user_tz":-480,"elapsed":5,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The capital of France is Paris. How may I assist you further?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}],"source":["response.choices[0].message.content"]},{"cell_type":"markdown","id":"5ba9c05d-d386-4731-8fcd-401d9ad713fc","metadata":{"id":"5ba9c05d-d386-4731-8fcd-401d9ad713fc"},"source":["## Message History with Assistant Content"]},{"cell_type":"code","execution_count":20,"id":"75696e0d-68cd-4da1-a140-47e5bd168934","metadata":{"id":"75696e0d-68cd-4da1-a140-47e5bd168934","executionInfo":{"status":"ok","timestamp":1735738251975,"user_tz":-480,"elapsed":977,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[],"source":["response = client.chat.completions.create(\n","    model = 'gpt-3.5-turbo',\n","    messages = [\n","    {'role':'system','content':'You are a polite customer support staff of Dynamics Inc.'},\n","    {'role':'user','content':'What is the capital of France?'},\n","        # NOTICE HOW WE CAN ADD THE EXPECTED ASSISTANT RESPONSE!\n","    {'role':'assistant','content':'Paris. Thank you for contacting Dynamics Inc.'},\n","    {'role':'user','content':\"What is the capital of Spain?\"},\n","     {'role':'assistant','content':\"Madrid. Thank you for contacting Dynamics Inc.\"},\n","        {'role':'user','content':\"What is the capital of Portugal?\"}\n","    # NOTICE HOW OUR LAST RESPONSE IS A 'role':'user' request!\n","    ]\n","\n",")"]},{"cell_type":"code","execution_count":21,"id":"629d9497-9487-432c-9d99-1c659c8732e1","metadata":{"id":"629d9497-9487-432c-9d99-1c659c8732e1","outputId":"195ef5e7-73d3-4d78-d9f2-56920bd5012b","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1735738253488,"user_tz":-480,"elapsed":418,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Lisbon. Thank you for contacting Dynamics Inc.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}],"source":["response.choices[0].message.content"]},{"cell_type":"markdown","id":"62eea043-38f6-4a19-b30d-da8623a8ec17","metadata":{"id":"62eea043-38f6-4a19-b30d-da8623a8ec17"},"source":["---\n","We can then also loop to provide historical message context:"]},{"cell_type":"code","execution_count":22,"id":"26cf4a72-0281-4948-a52a-b732c021dbd0","metadata":{"id":"26cf4a72-0281-4948-a52a-b732c021dbd0","outputId":"76700787-2de1-4986-f900-2dee3c2650fd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735738402757,"user_tz":-480,"elapsed":138810,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["BEST BUY SUPPORT CONVERSATION STARTED. TO END CONVERSATION TYPE 'BYE'\n","\n","\n","\n","what is the best laptop in levova?\n","\n","\n","As a customer support agent for Best Buy, I can recommend the Lenovo ThinkPad X1 Carbon as one of the best laptops in Lenovo's lineup. This laptop is known for its sleek design, powerful performance, and long battery life, making it a great option for business professionals and frequent travelers. It also offers a high-quality display, comfortable keyboard, and a variety of configuration options to suit different needs. If you have any specific requirements or budget in mind, feel free to let me know so I can further assist you in finding the best Lenovo laptop for your needs.\n","\n","\n","how is lenova ideapad 530s?\n","\n","\n","The Lenovo IdeaPad 530S is a mid-range laptop that offers a good balance of performance and affordability. It features a slim and lightweight design, making it a great option for users who are on the go. The laptop typically comes with an Intel Core i5 or i7 processor, which provides solid performance for everyday tasks such as web browsing, productivity applications, and multimedia consumption.\n","\n","In terms of display, the IdeaPad 530S usually comes with a Full HD (1920 x 1080) resolution screen that offers crisp visuals for media consumption and productivity work. The laptop also offers a decent selection of ports for connectivity, including USB Type-C, USB 3.0, HDMI, and an SD card reader.\n","\n","Overall, the Lenovo IdeaPad 530S is a solid choice for users looking for a reliable and budget-friendly laptop for everyday use. However, I recommend checking the latest model and reviews to ensure that it meets your specific requirements and expectations. If you need more detailed information or assistance, feel free to provide more details about your needs and preferences so I can better assist you.\n","\n","\n","which year model is it?\n","\n","\n","The Lenovo IdeaPad 530S was initially released in 2018. It is worth noting that there may have been updates or newer versions released since then, so I recommend checking with Lenovo's official website or authorized retailers for the most up-to-date information on the model availability and specifications. If you have a specific year in mind or are interested in a more recent update of the Lenovo IdeaPad 530S, please let me know so I can assist you further with finding the relevant information.\n","\n","\n","Thanks Bye\n","\n","\n","You're welcome! If you have any more questions in the future, feel free to reach out. Have a great day! Goodbye!\n","\n","\n","BYE\n","\n","\n","Goodbye!\n","\n","\n"]}],"source":["print(\"BEST BUY SUPPORT CONVERSATION STARTED. TO END CONVERSATION TYPE 'BYE'\\n\\n\\n\")\n","question = ''\n","\n","messages = [{'role':'system','content':'You are a customer support agent for Best Buy to help fix computer bugs'}]\n","\n","while question != 'BYE':\n","    # Get User Question\n","    question = input(\"\")  # Here input() class asks for user Q\n","\n","    # Add to messages/dialogue history\n","    messages.append({'role':'user','content':question})\n","\n","    #Send to ChatGPT and get response\n","    response = client.chat.completions.create(\n","          model=\"gpt-3.5-turbo\",\n","          messages=messages)\n","\n","    # Get content of assistant reply\n","    reply = response.choices[0].message.content\n","    print('\\n')\n","    print(reply)\n","    print('\\n')\n","    # Add assistant reply for dialogue history\n","    messages.append({'role':'assistant','content':reply})"]},{"cell_type":"markdown","id":"5ae88500-3990-4eda-8507-3a0bd8792c70","metadata":{"id":"5ae88500-3990-4eda-8507-3a0bd8792c70"},"source":["## Other Parameters"]},{"cell_type":"code","execution_count":23,"id":"b8876d21-a22a-4612-bf21-e8b53510ab05","metadata":{"id":"b8876d21-a22a-4612-bf21-e8b53510ab05","executionInfo":{"status":"ok","timestamp":1735738418095,"user_tz":-480,"elapsed":1246,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[],"source":["response = client.chat.completions.create(\n","    model = 'gpt-3.5-turbo',\n","    messages = [\n","    {'role':'system','content':'You are a story teller.'},\n","    {'role':'user','content':'What is the capital of France?'}\n","    ],\n","    temperature=1.2, # goes from 0-2\n","    max_tokens=1000,\n","\n",")"]},{"cell_type":"code","execution_count":24,"id":"17eb0b68-2ced-4818-86c5-99c4d2dd031f","metadata":{"id":"17eb0b68-2ced-4818-86c5-99c4d2dd031f","outputId":"9103fe8b-b9ad-43ad-d878-e90fc6b19b51","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735738419782,"user_tz":-480,"elapsed":2,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["The capital of France is Paris, known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre Dame Cathedral. It is a vibrant city filled with art, history, and culture.\n"]}],"source":["print(response.choices[0].message.content)"]},{"cell_type":"code","execution_count":25,"id":"1b5cdf8c-8d99-41d4-937b-b95e6f6f1cf6","metadata":{"id":"1b5cdf8c-8d99-41d4-937b-b95e6f6f1cf6","executionInfo":{"status":"ok","timestamp":1735738423824,"user_tz":-480,"elapsed":837,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[],"source":["response = client.chat.completions.create(\n","    model = 'gpt-3.5-turbo',\n","    messages = [\n","    {'role':'system','content':'You give short and direct answers.'},\n","    {'role':'user','content':'What is the capital of France?'}\n","    ],\n","    temperature=0, # goes from 0-2\n","    max_tokens=100,\n","\n",")"]},{"cell_type":"code","execution_count":26,"id":"86dab0e1-371e-4c24-b211-0dbd3034b328","metadata":{"id":"86dab0e1-371e-4c24-b211-0dbd3034b328","outputId":"6a2e02fe-d192-41ae-82ab-9a332358c885","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735738425111,"user_tz":-480,"elapsed":832,"user":{"displayName":"prabha Melady","userId":"18413778025838058766"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Paris.\n"]}],"source":["print(response.choices[0].message.content)"]},{"cell_type":"code","execution_count":null,"id":"97e838a6-0411-409a-8319-6bfcdb329055","metadata":{"id":"97e838a6-0411-409a-8319-6bfcdb329055"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}