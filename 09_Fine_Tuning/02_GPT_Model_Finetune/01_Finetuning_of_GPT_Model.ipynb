{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHigK0W58n13"
   },
   "source": [
    "#  **1. GPT Model Fine Tuning**\n",
    "\n",
    "- Here we are doing **GPT model** Finetuning\n",
    "- Here code written in COLAB\n",
    "- This script having some issue. didnt complete properly\n",
    "\n",
    "- **Link to gpt Fine Tuning methods:** https://platform.openai.com/docs/guides/fine-tuning/analyzing-your-fine-tuned-model\n",
    "\n",
    "  ![plot](./Planned_topic.png)\n",
    "\n",
    "### **Steps Followed**\n",
    "- Here 2 example provided , but both didnt work properly. just I/P dataset is different for training\n",
    "\n",
    "- Read sample data which used for fine tune\n",
    "- Create **fine tuning jobs** using training_file_id and model name\n",
    "- Run the Jobs **FineTuningJob**\n",
    "- Create the Jobs **Retrival**\n",
    "\n",
    "- In this step retrive the fine tuned model by its training_file_id\n",
    "- Inference by newly fine tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_Vzr1spBu3Z"
   },
   "source": [
    "# **EX 1:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2e4gPTe8x9t"
   },
   "source": [
    "## **Input formt needed for GPT Fine tune**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTr2zZQFKUBQ",
    "outputId": "ebb39325-e3b6-4725-d19b-beb06c25e49a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'Marv is a factual chatbot that is also sarcastic.'},\n",
       "  {'role': 'user', 'content': 'How far is the Moon from Earth?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Around 384,400 kilometers. Give or take a few, like that really matters.'}]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uce_AtjsMVbP",
    "outputId": "efcd6cf8-f5ac-4cb2-91da-27c1cc0bfb1e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' 3 Different Roles\\nsystem\\nuser\\nassistant'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 3 Different Roles\n",
    "system\n",
    "user\n",
    "assistant\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_CkJye0M_-u",
    "outputId": "09fbaa03-1abd-4987-ef0b-54f0d49ca76a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.7/360.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uG_RIZs9DSp"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQBch3UWNN65"
   },
   "outputs": [],
   "source": [
    "#Read openai KEY\n",
    "from google.colab import userdata\n",
    "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fknWrNoxNAFU"
   },
   "outputs": [],
   "source": [
    "#Connect to openai\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-wJGtZ49g_N"
   },
   "source": [
    "## Read sample data which used for fine tune\n",
    "- Manually created mydata.jsonl file in colab and copied this content.\n",
    "\n",
    "\n",
    "    - {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}\n",
    "\n",
    "- OpenAI need file in jsonl format, so created training data also in jason format **system, user, assistant**\n",
    "- kept file in jsonl-Jason line format\n",
    "- Using OPENAI Client, read jsonl file and create file in OPENAI with purpose=\"fine-tune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "em057z3wWbrm",
    "outputId": "b6df857b-c931-4f21-fa01-ed789f884ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jFdwOZomMdTj",
    "outputId": "822b78b7-42c3-49f6-e391-84f2b5261db1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-KQQWO0LvrSzNlWod9ikM72Gm', bytes=783, created_at=1723290649, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using OPENAI Client, read jsonl file and create file in OPENAI with purpose=\"fine-tune\"\n",
    "client.files.create(\n",
    "  file=open(\"mydata.jsonl\", \"rb\"),  #read in read and write form\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ms1leDCvQNMp",
    "outputId": "76d2f4d3-def5-4456-a7da-11f0e71f255f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[FileObject](data=[FileObject(id='file-efm77MfulshozgkrbGPIuNSA', bytes=783, created_at=1723288234, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-Zsu5ouWcFR2FMFojDdebgaY1', bytes=783, created_at=1723281846, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-L1rDfN3GYbk0K571jytNUpAr', bytes=783, created_at=1723279324, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-EkLgKnnAmyqXZmZzfXig9c3R', bytes=783, created_at=1723279265, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-EvtodK5hieWDr4wrNjJxHfzQ', bytes=783, created_at=1723278609, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-t3NvDoT1OwC1twIUGFoTLaUX', bytes=783, created_at=1723278420, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-An9ZxQFLFUsHTmCty6f1DZMS', bytes=783, created_at=1723277411, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-ncI3G9OCoPcrVCQxXtzfE3pM', bytes=783, created_at=1723277095, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-ZMXAYZslc7GBOvKGKweSAlvK', bytes=783, created_at=1723276992, filename='mydata.json', object='file', purpose='fine-tune', status='processed', status_details=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List of files in client\n",
    "files = client.files.list()\n",
    "files\n",
    "## Here script executed multiple time so multiple FileObject are there. Actually 1 to be created\n",
    "\n",
    "# SyncPage[FileObject](data=[FileObject(id='file-EvtodK5hieWDr4wrNjJxHfzQ', bytes=783,\n",
    "# created_at=1723278609, filename='mydata.jsonl', object='file', purpose='fine-tune',\n",
    "# status='processed', status_details=None),  object='list', has_more=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBQIZbSaQSOs"
   },
   "outputs": [],
   "source": [
    "#Get the training_file_id\n",
    "#Read urpose == \"fine-tune\" related files and set training_file_id = file.id\n",
    "for file in files:\n",
    "    if file.purpose == \"fine-tune\":\n",
    "        training_file_id = file.id   #id='efm77MfulshozgkrbGPIuNSA'\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "b60v0fyOQWDq",
    "outputId": "b706ff3e-0e94-490c-b6b0-d72f7cc13ed5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'file-efm77MfulshozgkrbGPIuNSA'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPQnce_6V0ad"
   },
   "source": [
    "## Create **fine tuning jobs** using training_file_id and model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "0Kc6g0PNQMJg",
    "outputId": "06e0c5ef-1008-48fd-b404-e20e4302b7c4"
   },
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Fine-tuning jobs cannot be created on an Explore plan. You can upgrade to a paid plan on your billing page: https://platform.openai.com/account/billing/overview', 'type': 'invalid_request_error', 'param': None, 'code': 'exceeded_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-08220bdc26f2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m client.fine_tuning.jobs.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtraining_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_file_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/fine_tuning/jobs/jobs.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, training_file, hyperparameters, integrations, seed, suffix, validation_file, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    131\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \"\"\"\n\u001b[0;32m--> 133\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;34m\"/fine_tuning/jobs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             body=maybe_transform(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 936\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    937\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         return self._process_response(\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Fine-tuning jobs cannot be created on an Explore plan. You can upgrade to a paid plan on your billing page: https://platform.openai.com/account/billing/overview', 'type': 'invalid_request_error', 'param': None, 'code': 'exceeded_quota'}}"
     ]
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyvQuNbk-uKg"
   },
   "source": [
    "### Run the Jobs **FineTuningJob**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5KAQKI9ObzU",
    "outputId": "4f37a28a-d2c0-422f-b598-66cbb299b2b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[], object='list', has_more=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fine tune the gpt turbo 3.5 model\n",
    "client.fine_tuning.jobs.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8i4H-CtrA31i"
   },
   "source": [
    "> In this step model will be fine tuned\n",
    "- here fined_model should not come as None, then it means its not yet fine tuned properly\n",
    "- This is the name of the fine tuned model - **model='gpt-3.5-turbo-0125'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwGAce4YAzCx"
   },
   "source": [
    "### Create the Jobs **Retrival**\n",
    "\n",
    "- In this step retrive the fine tuned model by its training_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59wgSPwgQwJJ",
    "outputId": "9c08ef80-ffd4-4c9b-f5f3-80f12c320874"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-QHPvVr4IMBVq0SIUOJK4byBz', created_at=1715491862, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=8, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=[], seed=1062020798, status='running', trained_tokens=None, training_file='file-k64fIU50AuG6luv3FZrhu0CS', validation_file=None, estimated_finish=1715492131, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy paste training_file_id = file-efm77MfulshozgkrbGPIuNSA\n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-QHPvVr4IMBVq0SIUOJK4byBz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dVedFYFAr8J"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ_tbNq9DDKR"
   },
   "source": [
    "## Inference by newly fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6XklRETQ0q4",
    "outputId": "50f1c1c2-3bc8-46e2-86f4-2d54635c58fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-0125\",  # Newly fine tuned model\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEMQGe4mBqEE"
   },
   "source": [
    "# **EX 2:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgI4T4fKCAcY"
   },
   "source": [
    "- Read csv file and convert ito json1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "n3G6lJKfS0nq",
    "outputId": "87b19dbb-4bae-4e5d-dae5-31c576184fe1"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/parenting_coach1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-913eed03e955>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Open the CSV file and read each line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mcsv_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/parenting_coach1.csv'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "# Replace 'your_path_here' with the path to the directory containing your file on Google Drive.\n",
    "# Make sure to keep '/content/drive/My Drive/' at the beginning.\n",
    "\n",
    "path_to_file = '/content/parenting_coach1.csv'\n",
    "output_path = '/content/parenting_coach1.jsonl'\n",
    "\n",
    "# Open the CSV file and read each line\n",
    "with open(path_to_file, 'r', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as jsonl_file:\n",
    "        for row in csv_reader:\n",
    "            json_str = row[0]\n",
    "            json_obj = json.loads(json_str)\n",
    "            jsonl_file.write(json.dumps(json_obj) + '\\n')\n",
    "\n",
    "print(f\"Conversion complete. The JSONL file is saved as '{output_path}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kk-GcQb2CGXR"
   },
   "source": [
    "## Read the jsnol file which holds finetuning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIndH3TVTmrK",
    "outputId": "aeb01461-32a1-4fcf-bf5b-47d902a4efdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-n8b1hgGcRpVnXxkKgzwynThB', bytes=12570, created_at=1715492298, filename='parenting_coach1.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "  file=open(\"/content/parenting_coach1.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siGqNB3YCMTh"
   },
   "source": [
    "## Create **fine tuning jobs** using training_file_id and model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7h_q4d08TvGO"
   },
   "outputs": [],
   "source": [
    "suffix_name = \"abc123\"\n",
    "response=client.fine_tuning.jobs.create(\n",
    "    training_file='file-n8b1hgGcRpVnXxkKgzwynThB',\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=suffix_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "uPLdUz8LnygE",
    "outputId": "bb59d99e-70ef-4c0a-ad67-8d6c4b67450e"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'FineTuningJob' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f95ba2e2c5ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjob_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'FineTuningJob' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "job_id = response[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54ILLZRMn1xx",
    "outputId": "6544cda1-6519-4e6d-ab46-778928fcf0a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-SgXfk2q90cvgzebEnzIsNPlq', created_at=1715497542, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=[], seed=1482830994, status='validating_files', trained_tokens=None, training_file='file-n8b1hgGcRpVnXxkKgzwynThB', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='abc123')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0eaMJkGCkaQ"
   },
   "source": [
    "### Run the Jobs **FineTuningJob**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPyUfgQsT4rH",
    "outputId": "fa51e6a9-c221-4ed6-a064-5f0d7f87457d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-SgXfk2q90cvgzebEnzIsNPlq', created_at=1715497542, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=[], seed=1482830994, status='running', trained_tokens=None, training_file='file-n8b1hgGcRpVnXxkKgzwynThB', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='abc123'), FineTuningJob(id='ftjob-Hw1m1YlzLPW8g5B9fHdKylij', created_at=1715492328, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9NwHXLDW', finished_at=1715492605, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=['file-nm0zADsethH70UJXOtcX4X0O'], seed=1839415463, status='succeeded', trained_tokens=6375, training_file='file-n8b1hgGcRpVnXxkKgzwynThB', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-QHPvVr4IMBVq0SIUOJK4byBz', created_at=1715491862, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9Nw9qxUu', finished_at=1715492129, hyperparameters=Hyperparameters(n_epochs=8, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=['file-x8OKDcMRw8sjYpwL0hkYnISy'], seed=1062020798, status='succeeded', trained_tokens=4640, training_file='file-k64fIU50AuG6luv3FZrhu0CS', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None), FineTuningJob(id='ftjob-ULIVUmwZt7Umeeis0CnvXLrT', created_at=1715491426, error=Error(code='invalid_n_examples', message='Training file has 3 example(s), but must have at least 10 examples', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-YHkBwO20EkoAAteP1i4EYNpZ', result_files=[], seed=1945097503, status='failed', trained_tokens=None, training_file='file-k10bwRjhXL488cvBee0c3TtW', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07JXOcWyGQPH"
   },
   "source": [
    "> This is the name of the fine tuned model - **model='gpt-3.5-turbo-0125'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAGUM9V8CpKp"
   },
   "source": [
    "### Create the Jobs **Retrival**\n",
    "\n",
    "- In this step retrive the fine tuned model by its training_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBtbT0ajoQCk"
   },
   "outputs": [],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "response=client.fine_tuning.jobs.retrieve('ftjob-SgXfk2q90cvgzebEnzIsNPlq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dszMwV0gpAmY"
   },
   "outputs": [],
   "source": [
    "response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "1OlXW9LmofTv",
    "outputId": "295b6e2a-f262-4648-f3c1-fee0f86235e1"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'FineTuningJob' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-01fc5fcba5db>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfine_tuned_model_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fine_tuned_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'FineTuningJob' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "fine_tuned_model_id = response[\"fine_tuned_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v25H9DuFoOJm"
   },
   "outputs": [],
   "source": [
    "#retrieve fine-tune model id\n",
    "response = openai.FineTuningJob.retrieve()\n",
    "fine_tuned_model_id = response[\"fine_tuned_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCL7vJcoDJWR"
   },
   "source": [
    "## Inference by newly fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z1sBpui9T9LP",
    "outputId": "dce8634f-1cdc-4f1b-80b0-81610eaf49b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"It's important to have a conversation with your son about why he is not doing his homework. Maybe there is an underlying issue that is bothering him or he is struggling with the material. Encourage him to talk to you about any challenges he may be facing so that you can offer support or help find a solution together. Setting up a routine or schedule for completing homework each day can also be helpful in establishing good study habits. Praise and reward your son when he does complete his homework to encourage positive behavior. If the issue persists, consider reaching out to his teacher or a school counselor for additional support.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model='gpt-3.5-turbo-0125', # Newly fine tuned model\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"my son does not do the homework what should i do?\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1jaSUUKGiip"
   },
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gawSzfSUd3Y",
    "outputId": "01e90f85-7204-4ae7-854f-0c3464766224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.28.1\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4cf7Ja8VJlJ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT = 'You are a teaching assistant for Machine Learning. You should help the user to answer his question.'\n",
    "\n",
    "def create_dataset(question, answer):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"path/to/file.csv\", encoding='cp1252')\n",
    "    with open(\"train.jsonl\", \"w\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            example_str = json.dumps(create_dataset(row[\"Question\"], row[\"Answer\"]))\n",
    "            f.write(example_str + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbZMJu6sp7z0"
   },
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "  file=open(\"/content/parenting_coach1.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsWWgykGqFvw"
   },
   "outputs": [],
   "source": [
    "job = client.fine_tuning.jobs.create(\n",
    "  training_file=file.id,\n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "bLSSWgmHqRsp",
    "outputId": "b5002dc1-2fc3-47ab-ecaf-9df0b9a2d0c6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'file-hPF7JXVlGnnDq3R4102pZn0c'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "osA8GBCwqV5y",
    "outputId": "1b71876e-80a9-4e51-9831-109ce1e6813e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'ftjob-egHhpjeb0FCFPGIiH4ztjNLU'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "875tcLc3qB-8"
   },
   "outputs": [],
   "source": [
    "job = client.fine_tuning.jobs.retrieve(job.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aYTAdAIeqZpP",
    "outputId": "1725e65b-dec5-4bf9-b6bf-e49bdd347e60"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'ft:gpt-3.5-turbo-0125:personal::9NxoM6CV'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0gADIzlqNO5",
    "outputId": "823f74d1-e54f-4a17-f47d-a9c0978f224b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Check all email settings, ensure internet connectivity, and consider contacting your email provider for further assistance.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=job.fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"how to fix email issue\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pusng9suqelW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
